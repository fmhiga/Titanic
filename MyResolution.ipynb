{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.name = 'Training Set'\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.name = 'Training Set'\n",
    "df_all = pd.concat([df_train, df_test], sort=True)\n",
    "df_all.name = 'All Set' \n",
    "df_all.reset_index(inplace=True, drop=True)\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                              Name     Sex   Age  SibSp  \\\n",
       "0          892       3                  Kelly, Mr. James    male  34.5      0   \n",
       "1          893       3  Wilkes, Mrs. James (Ellen Needs)  female  47.0      1   \n",
       "2          894       2         Myles, Mr. Thomas Francis    male  62.0      0   \n",
       "\n",
       "   Parch  Ticket    Fare Cabin Embarked  \n",
       "0      0  330911  7.8292   NaN        Q  \n",
       "1      0  363272  7.0000   NaN        S  \n",
       "2      0  240276  9.6875   NaN        Q  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      "Age            1046 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Name           1309 non-null object\n",
      "Parch          1309 non-null int64\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Sex            1309 non-null object\n",
      "SibSp          1309 non-null int64\n",
      "Survived       891 non-null float64\n",
      "Ticket         1309 non-null object\n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 97.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_missing(df):\n",
    "    print('{}'.format(df.name))\n",
    "    for col in df.columns.tolist():          \n",
    "        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "PassengerId column missing values: 0\n",
      "Survived column missing values: 0\n",
      "Pclass column missing values: 0\n",
      "Name column missing values: 0\n",
      "Sex column missing values: 0\n",
      "Age column missing values: 177\n",
      "SibSp column missing values: 0\n",
      "Parch column missing values: 0\n",
      "Ticket column missing values: 0\n",
      "Fare column missing values: 0\n",
      "Cabin column missing values: 687\n",
      "Embarked column missing values: 2\n",
      "\n",
      "\n",
      "Training Set\n",
      "PassengerId column missing values: 0\n",
      "Pclass column missing values: 0\n",
      "Name column missing values: 0\n",
      "Sex column missing values: 0\n",
      "Age column missing values: 86\n",
      "SibSp column missing values: 0\n",
      "Parch column missing values: 0\n",
      "Ticket column missing values: 0\n",
      "Fare column missing values: 1\n",
      "Cabin column missing values: 327\n",
      "Embarked column missing values: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_corr = df_all.corr().abs().unstack().sort_values(kind='quicksort', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_corr.rename(columns={'level_0':'Feature_1', 'level_1':'Feature_2', 0:'Coeficiente Correlation'}, inplace=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Coeficiente Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Age</td>\n",
       "      <td>Age</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Age</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.408106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Age</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.243699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Age</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.178740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Age</td>\n",
       "      <td>Parch</td>\n",
       "      <td>0.150917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Age</td>\n",
       "      <td>Survived</td>\n",
       "      <td>0.077221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Age</td>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0.028814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1    Feature_2  Coeficiente Correlation\n",
       "6        Age          Age                 1.000000\n",
       "9        Age       Pclass                 0.408106\n",
       "17       Age        SibSp                 0.243699\n",
       "22       Age         Fare                 0.178740\n",
       "25       Age        Parch                 0.150917\n",
       "29       Age     Survived                 0.077221\n",
       "41       Age  PassengerId                 0.028814"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_corr[df_all_corr['Feature_1']=='Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Pclass\n",
       "female  1         36.0\n",
       "        2         28.0\n",
       "        3         22.0\n",
       "male    1         42.0\n",
       "        2         29.5\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_by_pclass_sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>38.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>62.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>0</td>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age Cabin Embarked  Fare                                       Name  \\\n",
       "61   38.0   B28      NaN  80.0                        Icard, Miss. Amelie   \n",
       "829  62.0   B28      NaN  80.0  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "     Parch  PassengerId  Pclass     Sex  SibSp  Survived  Ticket  \n",
       "61       0           62       1  female      0       1.0  113572  \n",
       "829      0          830       1  female      0       1.0  113572  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>60.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>0</td>\n",
       "      <td>1044</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age Cabin Embarked  Fare                Name  Parch  PassengerId  \\\n",
       "1043  60.5   NaN        S   NaN  Storey, Mr. Thomas      0         1044   \n",
       "\n",
       "      Pclass   Sex  SibSp  Survived Ticket  \n",
       "1043       3  male      0       NaN   3701  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived     Ticket Deck  \n",
       "0       3    male      1       0.0  A/5 21171    M  \n",
       "1       1  female      1       1.0   PC 17599    C  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    1014\n",
       "C      94\n",
       "B      65\n",
       "D      46\n",
       "E      41\n",
       "A      22\n",
       "F      21\n",
       "G       5\n",
       "T       1\n",
       "Name: Deck, dtype: int64"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.Deck.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Deck'].loc[df_all['Deck'] == 'T'] = 'M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Cabin Embarked     Fare  \\\n",
       "0  22.0   NaN        S   7.2500   \n",
       "1  38.0   C85        C  71.2833   \n",
       "2  26.0   NaN        S   7.9250   \n",
       "3  35.0  C123        S  53.1000   \n",
       "4  35.0   NaN        S   8.0500   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "2                             Heikkinen, Miss. Laina      0            3   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n",
       "4                           Allen, Mr. William Henry      0            5   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived            Ticket Deck  \n",
       "0       3    male      1       0.0         A/5 21171    M  \n",
       "1       1  female      1       1.0          PC 17599    C  \n",
       "2       3  female      0       1.0  STON/O2. 3101282    M  \n",
       "3       1  female      1       1.0            113803    C  \n",
       "4       3    male      0       0.0            373450    M  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    1015\n",
       "C      94\n",
       "B      65\n",
       "D      46\n",
       "E      41\n",
       "A      22\n",
       "F      21\n",
       "G       5\n",
       "Name: Deck, dtype: int64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.Deck.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deck</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.593220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>G</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M</td>\n",
       "      <td>0.299419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Deck  Survived\n",
       "0    A  0.466667\n",
       "1    B  0.744681\n",
       "2    C  0.593220\n",
       "3    D  0.757576\n",
       "4    E  0.750000\n",
       "5    F  0.615385\n",
       "6    G  0.500000\n",
       "7    M  0.299419"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[['Deck','Survived']].groupby(['Deck'], as_index=False).mean().sort_values(by='Deck', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.drop(['Cabin'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Set\n",
      "Age column missing values: 0\n",
      "Embarked column missing values: 0\n",
      "Fare column missing values: 0\n",
      "Name column missing values: 0\n",
      "Parch column missing values: 0\n",
      "PassengerId column missing values: 0\n",
      "Pclass column missing values: 0\n",
      "Sex column missing values: 0\n",
      "SibSp column missing values: 0\n",
      "Survived column missing values: 418\n",
      "Ticket column missing values: 0\n",
      "Deck column missing values: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_missing(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Deck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>113803</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373450</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare                                               Name  \\\n",
       "0  22.0        S   7.2500                            Braund, Mr. Owen Harris   \n",
       "1  38.0        C  71.2833  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2  26.0        S   7.9250                             Heikkinen, Miss. Laina   \n",
       "3  35.0        S  53.1000       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4  35.0        S   8.0500                           Allen, Mr. William Henry   \n",
       "\n",
       "   Parch  PassengerId  Pclass     Sex  SibSp  Survived            Ticket Deck  \n",
       "0      0            1       3    male      1       0.0         A/5 21171    M  \n",
       "1      0            2       1  female      1       1.0          PC 17599    C  \n",
       "2      0            3       3  female      0       1.0  STON/O2. 3101282    M  \n",
       "3      0            4       1  female      1       1.0            113803    C  \n",
       "4      0            5       3    male      0       0.0            373450    M  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "df_test.drop(columns=['Survived'], inplace=True)\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    549\n",
       "1.0    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_corr = df_train.corr().abs().unstack().sort_values(kind='quicksort', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_corr.rename(columns={'level_0':'Feature_1', 'level_1':'Feature_2', 0:'Correlation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr['Correlation']==1.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Age</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.417667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Parch</td>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.414838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Survived</td>\n",
       "      <td>Pclass</td>\n",
       "      <td>0.338481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Survived</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.249747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Parch</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Age</td>\n",
       "      <td>Parch</td>\n",
       "      <td>0.176733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Age</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.124061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_1 Feature_2  Correlation\n",
       "8     Pclass      Fare     0.549500\n",
       "10       Age    Pclass     0.417667\n",
       "12     Parch     SibSp     0.414838\n",
       "14  Survived    Pclass     0.338481\n",
       "16  Survived      Fare     0.257307\n",
       "18     SibSp       Age     0.249747\n",
       "20     Parch      Fare     0.216225\n",
       "22       Age     Parch     0.176733\n",
       "24     SibSp      Fare     0.159651\n",
       "26       Age      Fare     0.124061"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df_train_corr_nd['Correlation'] > 0.1\n",
    "df_train_corr_nd[corr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_test], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Age'] = pd.qcut(df_all['Age'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(21.0, 25.0]</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>(-0.001, 7.896]</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(29.5, 40.0]</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>(31.275, 512.329]</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age Deck Embarked               Fare  \\\n",
       "0  (21.0, 25.0]    M        S    (-0.001, 7.896]   \n",
       "1  (29.5, 40.0]    C        C  (31.275, 512.329]   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived     Ticket  \n",
       "0       3    male      1       0.0  A/5 21171  \n",
       "1       1  female      1       1.0   PC 17599  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 7.896]      338\n",
       "(14.454, 31.275]     328\n",
       "(31.275, 512.329]    323\n",
       "(7.896, 14.454]      320\n",
       "Name: Fare, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Family_Size'] = df_all['Parch'] + df_all['SibSp'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Family_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(21.0, 25.0]</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>(-0.001, 7.896]</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(29.5, 40.0]</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>(31.275, 512.329]</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age Deck Embarked               Fare  \\\n",
       "0  (21.0, 25.0]    M        S    (-0.001, 7.896]   \n",
       "1  (29.5, 40.0]    C        C  (31.275, 512.329]   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived     Ticket  Family_Size  \n",
       "0       3    male      1       0.0  A/5 21171            2  \n",
       "1       1  female      1       1.0   PC 17599            2  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(21.0, 25.0]</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>(-0.001, 7.896]</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(29.5, 40.0]</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>(31.275, 512.329]</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age Deck Embarked               Fare  \\\n",
       "0  (21.0, 25.0]    M        S    (-0.001, 7.896]   \n",
       "1  (29.5, 40.0]    C        C  (31.275, 512.329]   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived     Ticket  Family_Size Title  \n",
       "0       3    male      1       0.0  A/5 21171            2    Mr  \n",
       "1       1  female      1       1.0   PC 17599            2   Mrs  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Title</th>\n",
       "      <th>Is_Married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(21.0, 25.0]</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>(-0.001, 7.896]</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(29.5, 40.0]</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>(31.275, 512.329]</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age Deck Embarked               Fare  \\\n",
       "0  (21.0, 25.0]    M        S    (-0.001, 7.896]   \n",
       "1  (29.5, 40.0]    C        C  (31.275, 512.329]   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived     Ticket  Family_Size Title  Is_Married  \n",
       "0       3    male      1       0.0  A/5 21171            2    Mr           0  \n",
       "1       1  female      1       1.0   PC 17599            2   Mrs           1  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              757\n",
       "Miss            260\n",
       "Mrs             197\n",
       "Master           61\n",
       "Rev               8\n",
       "Dr                8\n",
       "Col               4\n",
       "Mlle              2\n",
       "Major             2\n",
       "Ms                2\n",
       "Jonkheer          1\n",
       "Mme               1\n",
       "Don               1\n",
       "the Countess      1\n",
       "Dona              1\n",
       "Lady              1\n",
       "Sir               1\n",
       "Capt              1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Title'] .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Title']  = df_all['Title'].replace(['Lady', 'the Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "df_all['Title']  = df_all['Title'].replace('Mlle', 'Miss')\n",
    "df_all['Title']  = df_all['Title'].replace('Ms', 'Miss')\n",
    "df_all['Title']  = df_all['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr        757\n",
       "Miss      264\n",
       "Mrs       198\n",
       "Master     61\n",
       "Rare       29\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['Title'] .value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Is_Alone'] = 0\n",
    "df_all['Is_Alone'].loc[df_all['Family_Size'] == 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Title</th>\n",
       "      <th>Is_Married</th>\n",
       "      <th>Family_Size_Grouped</th>\n",
       "      <th>Is_Alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(21.0, 25.0]</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>(-0.001, 7.896]</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(29.5, 40.0]</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>(31.275, 512.329]</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age Deck Embarked               Fare  \\\n",
       "0  (21.0, 25.0]    M        S    (-0.001, 7.896]   \n",
       "1  (29.5, 40.0]    C        C  (31.275, 512.329]   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived     Ticket  Family_Size Title  Is_Married  \\\n",
       "0       3    male      1       0.0  A/5 21171            2    Mr           0   \n",
       "1       1  female      1       1.0   PC 17599            2   Mrs           1   \n",
       "\n",
       "  Family_Size_Grouped  Is_Alone  \n",
       "0               Small         0  \n",
       "1               Small         0  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 17)\n",
      "(418, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Title</th>\n",
       "      <th>Is_Married</th>\n",
       "      <th>Family_Size_Grouped</th>\n",
       "      <th>Is_Alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(21.0, 25.0]</td>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>(-0.001, 7.896]</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>2</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(29.5, 40.0]</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>(31.275, 512.329]</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "      <td>Small</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age Deck Embarked               Fare  \\\n",
       "0  (21.0, 25.0]    M        S    (-0.001, 7.896]   \n",
       "1  (29.5, 40.0]    C        C  (31.275, 512.329]   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass     Sex  SibSp  Survived     Ticket  Family_Size Title  Is_Married  \\\n",
       "0       3    male      1       0.0  A/5 21171            2    Mr           0   \n",
       "1       1  female      1       1.0   PC 17599            2   Mrs           1   \n",
       "\n",
       "  Family_Size_Grouped  Is_Alone  \n",
       "0               Small         0  \n",
       "1               Small         0  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Label Enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "str_features = ['Age','Deck','Embarked','Fare','Sex', 'Title', 'Family_Size_Grouped']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in str_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['Deck','Embarked','Sex','Pclass', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[6:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 42)\n",
      "(418, 42)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Title_1</th>\n",
       "      <th>Title_2</th>\n",
       "      <th>Title_3</th>\n",
       "      <th>Title_4</th>\n",
       "      <th>Title_5</th>\n",
       "      <th>Family_Size_Grouped_1</th>\n",
       "      <th>Family_Size_Grouped_2</th>\n",
       "      <th>Family_Size_Grouped_3</th>\n",
       "      <th>Family_Size_Grouped_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Deck  Embarked  Fare  \\\n",
       "0    1     7         2     0   \n",
       "1    3     2         0     3   \n",
       "\n",
       "                                                Name  Parch  PassengerId  \\\n",
       "0                            Braund, Mr. Owen Harris      0            1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n",
       "\n",
       "   Pclass  Sex  SibSp          ...            Pclass_3 Title_1  Title_2  \\\n",
       "0       3    1      1          ...                 1.0     0.0      0.0   \n",
       "1       1    0      1          ...                 0.0     0.0      0.0   \n",
       "\n",
       "   Title_3  Title_4  Title_5  Family_Size_Grouped_1  Family_Size_Grouped_2  \\\n",
       "0      1.0      0.0      0.0                    0.0                    0.0   \n",
       "1      0.0      1.0      0.0                    0.0                    0.0   \n",
       "\n",
       "   Family_Size_Grouped_3  Family_Size_Grouped_4  \n",
       "0                    0.0                    1.0  \n",
       "1                    0.0                    1.0  \n",
       "\n",
       "[2 rows x 42 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['Name', 'Ticket', 'PassengerId', 'Pclass', 'Sex', 'Embarked', 'Title', 'Family_Size', 'Family_Size_Grouped', 'SibSp', 'Parch', 'Deck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=drop_cols)\n",
    "df_test = df_test.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 30)\n",
      "(418, 30)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_train.drop(\"Survived\", axis=1)\n",
    "y = df_train[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predict Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  83.47\n",
      "0.879694941822\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log = round(logreg.score(X_train, y_train) * 100, 2)\n",
    "print('Accuracy: ', acc_log)\n",
    "print(roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  91.65\n",
      "AUC:  0.793693856635\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = round(decision_tree.score(X_train, y_train) * 100, 2)\n",
    "print('Accuracy: ', acc_decision_tree)\n",
    "print('AUC: ', roc_auc_score(y_test, decision_tree.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  91.65\n",
      "AUC:  0.855579670827\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "acc_random_forest = round(random_forest.score(X_train, y_train) * 100, 2)\n",
    "print('Accuracy: ', acc_random_forest)\n",
    "print('AUC: ', roc_auc_score(y_test, random_forest.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 700 out of 700 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier oob score: 0.8105939004815409\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='gini', \n",
    "                            n_estimators=700,\n",
    "                            max_depth=4,\n",
    "                            min_samples_split=19,\n",
    "                            min_samples_leaf=6, \n",
    "                            max_features='auto', \n",
    "                            oob_score=True, \n",
    "                            n_jobs=-1,\n",
    "                            verbose=1) \n",
    "\n",
    "clf.fit(StandardScaler().fit_transform(X_train), y_train)\n",
    "print('RandomForestClassifier oob score: {}'.format(clf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.88      0.88       171\n",
      "        1.0       0.79      0.76      0.77        97\n",
      "\n",
      "avg / total       0.84      0.84      0.84       268\n",
      "\n",
      "0.884517996021\n"
     ]
    }
   ],
   "source": [
    "# Boosting\n",
    "from sklearn import ensemble\n",
    "params = {'n_estimators': 500, 'max_depth': 2, 'min_samples_split': 2,\n",
    "          'learning_rate': 0.01}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'learning_rate': [0.001, 0.01, 0.1],\n",
    "                     'max_depth' : [1, 3, 10],\n",
    "                     'min_samples_split': [2, 10],\n",
    "                     'n_estimators': [10, 100, 500],\n",
    "                     'subsample': [0.5, 1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.808, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.776, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.782258064516129, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.75, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.808, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.776, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.782258064516129, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.75, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.808, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.776, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.782258064516129, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.75, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.808, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.776, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.782258064516129, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.75, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.76, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.752, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.816, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.782258064516129, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8145161290322581, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.768, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.768, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.784, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.782258064516129, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.7661290322580645, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.768, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.76, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.816, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.7983870967741935, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.7983870967741935, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.768, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.768, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.784, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.782258064516129, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.7661290322580645, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.608, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.608, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.4s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.784, total=   2.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.776, total=   2.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.832, total=   2.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8306451612903226, total=   2.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8387096774193549, total=   2.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.784, total=   2.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.76, total=   2.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.792, total=   2.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8225806451612904, total=   2.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8387096774193549, total=   2.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.608, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.6048387096774194, total=   0.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.3s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.608, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.6048387096774194, total=   0.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.792, total=   1.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.784, total=   1.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.856, total=   1.2s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8306451612903226, total=   1.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8306451612903226, total=   1.1s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8, total=   1.7s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.768, total=   1.7s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.792, total=   1.8s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8306451612903226, total=   1.6s\n",
      "[CV] learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.001, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8548387096774194, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.848, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.824, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.7983870967741935, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.782258064516129, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.848, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.808, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.7983870967741935, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.7580645161290323, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.856, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.824, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.7983870967741935, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.782258064516129, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.848, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.8, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.808, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.7983870967741935, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.7580645161290323, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.792, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.76, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.848, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8145161290322581, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.7983870967741935, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.76, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.8064516129032258, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.7741935483870968, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.776, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.816, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8387096774193549, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.7983870967741935, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.808, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.784, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.832, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.8306451612903226, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.7983870967741935, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.824, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.768, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.832, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8064516129032258, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.7983870967741935, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.76, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.8064516129032258, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.7741935483870968, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.784, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.776, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.824, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8387096774193549, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.7983870967741935, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.808, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.784, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.84, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.8306451612903226, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.7983870967741935, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.76, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.832, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8306451612903226, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8387096774193549, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.776, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.784, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.8306451612903226, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.8306451612903226, total=   0.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.824, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.776, total=   2.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.808, total=   2.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8225806451612904, total=   2.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8387096774193549, total=   2.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.808, total=   2.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.76, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.776, total=   2.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8225806451612904, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8387096774193549, total=   2.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.608, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.6048387096774194, total=   0.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.784, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.792, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.848, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8387096774193549, total=   0.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8306451612903226, total=   0.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.808, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.752, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.8064516129032258, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.8387096774193549, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.824, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.776, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.808, total=   1.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8225806451612904, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8145161290322581, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.816, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.752, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.816, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8225806451612904, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.01, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8306451612903226, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.792, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=10, subsample=1, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.864, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.816, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.84, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.7903225806451613, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.848, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.792, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.84, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=100, subsample=1, score=0.7903225806451613, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.856, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.832, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.824, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8306451612903226, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.7903225806451613, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.856, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.84, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.824, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.8306451612903226, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=2, n_estimators=500, subsample=1, score=0.782258064516129, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.792, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.792, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.776, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=10, subsample=1, score=0.75, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.864, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.832, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.848, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.792, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.84, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=100, subsample=1, score=0.7903225806451613, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.856, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.832, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.816, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8306451612903226, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.7903225806451613, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.856, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.84, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.824, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.8306451612903226, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=1, min_samples_split=10, n_estimators=500, subsample=1, score=0.782258064516129, total=   0.1s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.784, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.84, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.7983870967741935, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.7903225806451613, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.76, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.8064516129032258, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=10, subsample=1, score=0.7741935483870968, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.784, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.832, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8225806451612904, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.7903225806451613, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.824, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.768, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.832, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.8387096774193549, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=100, subsample=1, score=0.8064516129032258, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.776, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.84, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8225806451612904, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8387096774193549, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.816, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.768, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.808, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.8225806451612904, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=2, n_estimators=500, subsample=1, score=0.8225806451612904, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.752, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.824, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.8225806451612904, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.782258064516129, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.76, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.808, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.8064516129032258, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=10, subsample=1, score=0.7741935483870968, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.824, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.784, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.832, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.7983870967741935, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.832, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.784, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.84, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=100, subsample=1, score=0.7903225806451613, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.784, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.832, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8145161290322581, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8145161290322581, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.808, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.784, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.816, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.8145161290322581, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=3, min_samples_split=10, n_estimators=500, subsample=1, score=0.8145161290322581, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.792, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.752, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.8387096774193549, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=0.5, score=0.7903225806451613, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.784, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.784, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=10, subsample=1, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.824, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.776, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.776, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8225806451612904, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=0.5, score=0.8467741935483871, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.8, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.768, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.784, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.8145161290322581, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=100, subsample=1, score=0.8306451612903226, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.808, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.784, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8145161290322581, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=0.5, score=0.8467741935483871, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.776, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8145161290322581, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=2, n_estimators=500, subsample=1, score=0.8306451612903226, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.816, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.848, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.8467741935483871, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=0.5, score=0.8306451612903226, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.816, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.76, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.8, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.8064516129032258, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=10, subsample=1, score=0.8467741935483871, total=   0.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.816, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.776, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8306451612903226, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=0.5, score=0.8387096774193549, total=   0.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.808, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.76, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.8, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.8225806451612904, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=100, subsample=1, score=0.8467741935483871, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.816, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.784, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.792, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8225806451612904, total=   1.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=0.5, score=0.8467741935483871, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.76, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8225806451612904, total=   1.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1 \n",
      "[CV]  learning_rate=0.1, max_depth=10, min_samples_split=10, n_estimators=500, subsample=1, score=0.8225806451612904, total=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'learning_rate': [0.001, 0.01, 0.1], 'max_depth': [1, 3, 10], 'min_samples_split': [2, 10], 'n_estimators': [10, 100, 500], 'subsample': [0.5, 1]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(ensemble.GradientBoostingClassifier(), tuned_parameters, cv=5, verbose=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.001, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.785 (+/-0.053) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.774 (+/-0.016) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.788 (+/-0.042) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.774 (+/-0.016) for {'learning_rate': 0.001, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.812 (+/-0.053) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.799 (+/-0.056) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.819 (+/-0.054) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.809 (+/-0.061) for {'learning_rate': 0.001, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.811 (+/-0.046) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.803 (+/-0.057) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.812 (+/-0.051) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.803 (+/-0.057) for {'learning_rate': 0.01, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.803 (+/-0.058) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.791 (+/-0.041) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.806 (+/-0.042) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.811 (+/-0.037) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.806 (+/-0.045) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.791 (+/-0.041) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.804 (+/-0.047) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.812 (+/-0.041) for {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.812 (+/-0.059) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.804 (+/-0.046) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.814 (+/-0.043) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.801 (+/-0.058) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.607 (+/-0.003) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.819 (+/-0.052) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.801 (+/-0.056) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.809 (+/-0.035) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.807 (+/-0.057) for {'learning_rate': 0.01, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.783 (+/-0.040) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.782 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.828 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.820 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.827 (+/-0.042) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.827 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.782 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.782 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.823 (+/-0.054) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.820 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.825 (+/-0.043) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.827 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 1, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.803 (+/-0.039) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.790 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.806 (+/-0.037) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.814 (+/-0.051) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.815 (+/-0.049) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.807 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.798 (+/-0.055) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.790 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.814 (+/-0.038) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.815 (+/-0.047) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.809 (+/-0.032) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.807 (+/-0.024) for {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "0.795 (+/-0.055) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.806 (+/-0.042) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1}\n",
      "0.809 (+/-0.057) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.799 (+/-0.044) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1}\n",
      "0.811 (+/-0.041) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.804 (+/-0.036) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 500, 'subsample': 1}\n",
      "0.828 (+/-0.037) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 0.5}\n",
      "0.806 (+/-0.056) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10, 'subsample': 1}\n",
      "0.812 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 0.5}\n",
      "0.807 (+/-0.057) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'subsample': 1}\n",
      "0.812 (+/-0.045) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 0.5}\n",
      "0.801 (+/-0.046) for {'learning_rate': 0.1, 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 500, 'subsample': 1}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.87      0.89      0.88       171\n",
      "        1.0       0.80      0.77      0.79        97\n",
      "\n",
      "avg / total       0.85      0.85      0.85       268\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "        % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "print(classification_report(y_test, clf.predict(X_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873244106831\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(StandardScaler().fit_transform(df_test)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PassengerId = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission_df['PassengerId'] = PassengerId['PassengerId']\n",
    "submission_df['Survived'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1\n",
       "5          897         0\n",
       "6          898         1\n",
       "7          899         0\n",
       "8          900         1\n",
       "9          901         0"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.to_csv('submissions.csv', header=True, index=False)\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
